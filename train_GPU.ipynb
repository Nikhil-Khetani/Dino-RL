{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9e/sbXcUajLwRA/hfMGdQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhil-Khetani/Dino-RL/blob/main/train_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VkFrzP7Dau8",
        "outputId": "71f9bf04-3a1f-4d30-d8ab-85f4f85fb953"
      },
      "source": [
        "!pip install pygame"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygame\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/da/4ff439558641a26dd29b04c25947e6c0ace041f56b2aa2ef1134edab06b8/pygame-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (11.8MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8MB 271kB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkoe3seEDgUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "472b256a-577e-4967-9c19-b60c20c3d033"
      },
      "source": [
        "import cv2\r\n",
        "import time \r\n",
        "import os, sys\r\n",
        "import game\r\n",
        "import math\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "from collections import namedtuple\r\n",
        "from itertools import count\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision.transforms as T\r\n",
        "import pygame\r\n",
        "import time"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuTd3rk_Dmct"
      },
      "source": [
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkpZyQ-9Dq48"
      },
      "source": [
        "\r\n",
        "\r\n",
        "\r\n",
        "DISPLAY_HEIGHT=400\r\n",
        "DISPLAY_WIDTH=400\r\n",
        "STATE_HEIGHT = DISPLAY_HEIGHT-1\r\n",
        "STATE_WIDTH = DISPLAY_WIDTH-1\r\n",
        "\r\n",
        "pygame.init()\r\n",
        "\r\n",
        "image_size=84\r\n",
        "batch_size=32\r\n",
        "lr=1e-6\r\n",
        "gamma=0.99\r\n",
        "initial_epsilon=0.1\r\n",
        "final_epsilon=1e-4\r\n",
        "num_iters=2000000\r\n",
        "replay_memory_size=50000"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAC26h3MFwMq"
      },
      "source": [
        "\r\n",
        "Transition = namedtuple('Transition',('state', 'action', 'next_state', 'reward'))\r\n",
        "\r\n",
        "def pre_processing(image, width, height):\r\n",
        "    image = cv2.cvtColor(cv2.resize(image, (width, height)), cv2.COLOR_BGR2GRAY)\r\n",
        "    _, image = cv2.threshold(image, 1, 255, cv2.THRESH_BINARY)\r\n",
        "    return image[None, :, :].astype(np.float32)\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkoOWRKMFV71"
      },
      "source": [
        "\r\n",
        "class DeepQNetwork(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(DeepQNetwork, self).__init__()\r\n",
        "\r\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(4, 32, kernel_size=8, stride=4), nn.ReLU(inplace=True))\r\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(inplace=True))\r\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1), nn.ReLU(inplace=True))\r\n",
        "\r\n",
        "        self.fc1 = nn.Sequential(nn.Linear(7 * 7 * 64, 512), nn.ReLU(inplace=True))\r\n",
        "        self.fc2 = nn.Linear(512, 2)\r\n",
        "        self._create_weights()\r\n",
        "\r\n",
        "    def _create_weights(self):\r\n",
        "        for m in self.modules():\r\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\r\n",
        "                nn.init.uniform(m.weight, -0.01, 0.01)\r\n",
        "                nn.init.constant_(m.bias, 0)\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        output = self.conv1(input)\r\n",
        "        output = self.conv2(output)\r\n",
        "        output = self.conv3(output)\r\n",
        "        output = output.view(output.size(0), -1)\r\n",
        "        output = self.fc1(output)\r\n",
        "        output = self.fc2(output)\r\n",
        "\r\n",
        "        return output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49ZgrRJgFcFM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "01e8f806-f817-435a-94dd-f79ff79ef4e3"
      },
      "source": [
        "\n",
        "def train(episodes):\n",
        "    real_time_start = time.time()\n",
        "    CPU_time_start = time.process_time()\n",
        "    model = DeepQNetwork()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    current_game = game.DinoGame(None,400,400)\n",
        "    image, reward, endgame = current_game.nextframe(0)\n",
        "    \n",
        "    image = pre_processing(image, 84,84)\n",
        "    #image = torch.from_numpy(np.expand_dims(np.transpose(image,(2,0,1)),0))\n",
        "    image = torch.from_numpy(image)\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "        image = image.cuda()\n",
        "    #image=image.float()\n",
        "    state=torch.cat(tuple(image for _ in range (4)))[None, :, :, :]\n",
        "    #print(state.shape)\n",
        "    replay_memory = []\n",
        "    episode = 0\n",
        "    checkpoint_real_time_elapsed = 0\n",
        "    checkpoint_CPU_time_elapsed = 0\n",
        "\n",
        "\n",
        "    for i in reversed(range(1000)):\n",
        "      print(i)\n",
        "      checkpoint_path = \"checkpoint_{}.pt\".format(i*1000)\n",
        "      if os.path.exists(checkpoint_path):\n",
        "          checkpoint = torch.load(checkpoint_path,map_location=torch.device('cpu'))\n",
        "          model.load_state_dict(checkpoint['model_state_dict'])\n",
        "          optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "          episode = checkpoint['checkpoint_episode']\n",
        "          loss = checkpoint['loss']\n",
        "          checkpoint_real_time_elapsed = checkpoint['real_time_elapsed']\n",
        "          checkpoint_CPU_time_elapsed = checkpoint['CPU_time_elapsed']\n",
        "          print(\"checkpoint loaded\")\n",
        "          print(\"checkpoint episode:\" + str(episode))\n",
        "          break\n",
        "    \n",
        "    while episode<episodes:\n",
        "        pred = model(state)[0]\n",
        "        epsilon = final_epsilon+((episodes-episode)*(initial_epsilon-final_epsilon)/episodes)\n",
        "        take_random_action = random.random()<=epsilon\n",
        "        if take_random_action:\n",
        "            print('random')\n",
        "            action = random.randint(0,1)\n",
        "        else:\n",
        "            action=torch.argmax(pred)\n",
        "\n",
        "        next_image, reward, endgame = current_game.nextframe(action)\n",
        "        #next_image = torch.from_numpy(np.expand_dims(np.transpose(next_image,(2,0,1)),0))\n",
        "        #next_image = next_image.float()\n",
        "        #next_state = torch.cat((state.squeeze(0)[3:,:,:], next_image))\n",
        "\n",
        "        next_image = pre_processing(next_image, 84,84)\n",
        "\n",
        "        #action = action.unsqueeze(0)\n",
        "        #reward = torch.from_numpy(np.array([reward],dtype=np.float32)).unsqueeze(0)\n",
        "        next_image = torch.from_numpy(next_image)\n",
        "        if torch.cuda.is_available():\n",
        "            next_image = next_image.cuda()\n",
        "        next_state = torch.cat((state[0, 1:, :, :], next_image))[None, :, :, :]\n",
        "\n",
        "        replay_memory.append([state, action, reward, next_state, endgame])\n",
        "        if len(replay_memory) > replay_memory_size:\n",
        "            del replay_memory[0]\n",
        "        batch = random.sample(replay_memory, min(len(replay_memory), batch_size))\n",
        "        state_batch, action_batch, reward_batch, next_state_batch, terminal_batch = zip(*batch)\n",
        "        state_batch = torch.cat(tuple(state for state in state_batch))\n",
        "        action_batch = torch.from_numpy(\n",
        "            np.array([[1, 0] if action == 0 else [0, 1] for action in action_batch], dtype=np.float32))\n",
        "        reward_batch = torch.from_numpy(np.array(reward_batch, dtype=np.float32)[:, None])\n",
        "        next_state_batch = torch.cat(tuple(state for state in next_state_batch))\n",
        "        if torch.cuda.is_available():\n",
        "            state_batch = state_batch.cuda()\n",
        "            action_batch = action_batch.cuda()\n",
        "            reward_batch = reward_batch.cuda()\n",
        "            next_state_batch = next_state_batch.cuda()\n",
        "        \n",
        "        current_prediction_batch = model(state_batch)\n",
        "        next_prediction_batch = model(next_state_batch)\n",
        "\n",
        "        y_batch = torch.cat(\n",
        "            tuple(reward if terminal else reward + gamma * torch.max(prediction) for reward, terminal, prediction in\n",
        "                  zip(reward_batch, terminal_batch, next_prediction_batch)))\n",
        "        q_value = torch.sum(current_prediction_batch * action_batch, dim=1)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(q_value, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        state = next_state\n",
        "        \n",
        "        if episode %50 == 0:\n",
        "            print(\"Episode: {}/{}, Action: {}, Loss: {}, Epsilon {}, Reward: {}, Q-value: {}\".format(\n",
        "            episode + 1, episodes, action, loss, epsilon, reward, torch.max(pred)))\n",
        "        episode+=1\n",
        "\n",
        "        if episode % 5000 == 0:\n",
        "            real_time_elapsed = time.time()-real_time_start + checkpoint_real_time_elapsed\n",
        "            CPU_time_elapsed =time.process_time()-CPU_time_start + checkpoint_CPU_time_elapsed\n",
        "            print(\"Real time elapsed : {}, CPU time elapsed : {}\".format(real_time_elapsed,CPU_time_elapsed))\n",
        "            checkpoint_path = \"checkpoint_{}.pt\".format(episode)\n",
        "            torch.save({\n",
        "            'checkpoint_episode': episode,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss':loss,\n",
        "            'real_time_elapsed' : real_time_elapsed,\n",
        "            'CPU_time_elapsed' : CPU_time_elapsed\n",
        "            }, checkpoint_path)\n",
        "\n",
        "\n",
        "train(1000000)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "999\n",
            "998\n",
            "997\n",
            "996\n",
            "995\n",
            "994\n",
            "993\n",
            "992\n",
            "991\n",
            "990\n",
            "989\n",
            "988\n",
            "987\n",
            "986\n",
            "985\n",
            "984\n",
            "983\n",
            "982\n",
            "981\n",
            "980\n",
            "979\n",
            "978\n",
            "977\n",
            "976\n",
            "975\n",
            "974\n",
            "973\n",
            "972\n",
            "971\n",
            "970\n",
            "969\n",
            "968\n",
            "967\n",
            "966\n",
            "965\n",
            "964\n",
            "963\n",
            "962\n",
            "961\n",
            "960\n",
            "959\n",
            "958\n",
            "957\n",
            "956\n",
            "955\n",
            "954\n",
            "953\n",
            "952\n",
            "951\n",
            "950\n",
            "949\n",
            "948\n",
            "947\n",
            "946\n",
            "945\n",
            "944\n",
            "943\n",
            "942\n",
            "941\n",
            "940\n",
            "939\n",
            "938\n",
            "937\n",
            "936\n",
            "935\n",
            "934\n",
            "933\n",
            "932\n",
            "931\n",
            "930\n",
            "929\n",
            "928\n",
            "927\n",
            "926\n",
            "925\n",
            "924\n",
            "923\n",
            "922\n",
            "921\n",
            "920\n",
            "919\n",
            "918\n",
            "917\n",
            "916\n",
            "915\n",
            "914\n",
            "913\n",
            "912\n",
            "911\n",
            "910\n",
            "909\n",
            "908\n",
            "907\n",
            "906\n",
            "905\n",
            "904\n",
            "903\n",
            "902\n",
            "901\n",
            "900\n",
            "899\n",
            "898\n",
            "897\n",
            "896\n",
            "895\n",
            "894\n",
            "893\n",
            "892\n",
            "891\n",
            "890\n",
            "889\n",
            "888\n",
            "887\n",
            "886\n",
            "885\n",
            "884\n",
            "883\n",
            "882\n",
            "881\n",
            "880\n",
            "879\n",
            "878\n",
            "877\n",
            "876\n",
            "875\n",
            "874\n",
            "873\n",
            "872\n",
            "871\n",
            "870\n",
            "869\n",
            "868\n",
            "867\n",
            "866\n",
            "865\n",
            "864\n",
            "863\n",
            "862\n",
            "861\n",
            "860\n",
            "859\n",
            "858\n",
            "857\n",
            "856\n",
            "855\n",
            "854\n",
            "853\n",
            "852\n",
            "851\n",
            "850\n",
            "849\n",
            "848\n",
            "847\n",
            "846\n",
            "845\n",
            "844\n",
            "843\n",
            "842\n",
            "841\n",
            "840\n",
            "839\n",
            "838\n",
            "837\n",
            "836\n",
            "835\n",
            "834\n",
            "833\n",
            "832\n",
            "831\n",
            "830\n",
            "829\n",
            "828\n",
            "827\n",
            "826\n",
            "825\n",
            "824\n",
            "823\n",
            "822\n",
            "821\n",
            "820\n",
            "819\n",
            "818\n",
            "817\n",
            "816\n",
            "815\n",
            "814\n",
            "813\n",
            "812\n",
            "811\n",
            "810\n",
            "809\n",
            "808\n",
            "807\n",
            "806\n",
            "805\n",
            "804\n",
            "803\n",
            "802\n",
            "801\n",
            "800\n",
            "799\n",
            "798\n",
            "797\n",
            "796\n",
            "795\n",
            "794\n",
            "793\n",
            "792\n",
            "791\n",
            "790\n",
            "789\n",
            "788\n",
            "787\n",
            "786\n",
            "785\n",
            "784\n",
            "783\n",
            "782\n",
            "781\n",
            "780\n",
            "779\n",
            "778\n",
            "777\n",
            "776\n",
            "775\n",
            "774\n",
            "773\n",
            "772\n",
            "771\n",
            "770\n",
            "769\n",
            "768\n",
            "767\n",
            "766\n",
            "765\n",
            "764\n",
            "763\n",
            "762\n",
            "761\n",
            "760\n",
            "759\n",
            "758\n",
            "757\n",
            "756\n",
            "755\n",
            "754\n",
            "753\n",
            "752\n",
            "751\n",
            "750\n",
            "749\n",
            "748\n",
            "747\n",
            "746\n",
            "745\n",
            "744\n",
            "743\n",
            "742\n",
            "741\n",
            "740\n",
            "739\n",
            "738\n",
            "737\n",
            "736\n",
            "735\n",
            "734\n",
            "733\n",
            "732\n",
            "731\n",
            "730\n",
            "729\n",
            "728\n",
            "727\n",
            "726\n",
            "725\n",
            "724\n",
            "723\n",
            "722\n",
            "721\n",
            "720\n",
            "719\n",
            "718\n",
            "717\n",
            "716\n",
            "715\n",
            "714\n",
            "713\n",
            "712\n",
            "711\n",
            "710\n",
            "709\n",
            "708\n",
            "707\n",
            "706\n",
            "705\n",
            "704\n",
            "703\n",
            "702\n",
            "701\n",
            "700\n",
            "699\n",
            "698\n",
            "697\n",
            "696\n",
            "695\n",
            "694\n",
            "693\n",
            "692\n",
            "691\n",
            "690\n",
            "689\n",
            "688\n",
            "687\n",
            "686\n",
            "685\n",
            "684\n",
            "683\n",
            "682\n",
            "681\n",
            "680\n",
            "679\n",
            "678\n",
            "677\n",
            "676\n",
            "675\n",
            "674\n",
            "673\n",
            "672\n",
            "671\n",
            "670\n",
            "669\n",
            "668\n",
            "667\n",
            "666\n",
            "665\n",
            "664\n",
            "663\n",
            "662\n",
            "661\n",
            "660\n",
            "659\n",
            "658\n",
            "657\n",
            "656\n",
            "655\n",
            "654\n",
            "653\n",
            "652\n",
            "651\n",
            "650\n",
            "649\n",
            "648\n",
            "647\n",
            "646\n",
            "645\n",
            "checkpoint loaded\n",
            "checkpoint episode:645000\n",
            "Episode: 645001/1000000, Action: 0, Loss: 0.08681347221136093, Epsilon 0.035564500000000006, Reward: 0.3, Q-value: 0.5358766317367554\n",
            "random\n",
            "Episode: 645051/1000000, Action: 0, Loss: 0.08904650807380676, Epsilon 0.035559505, Reward: 0.3, Q-value: 0.8509565591812134\n",
            "random\n",
            "random\n",
            "Episode: 645101/1000000, Action: 0, Loss: 0.08514119684696198, Epsilon 0.035554510000000004, Reward: 0.3, Q-value: 0.6625964045524597\n",
            "random\n",
            "Episode: 645151/1000000, Action: 0, Loss: 0.08625850081443787, Epsilon 0.035549515000000004, Reward: 0.3, Q-value: 1.0154647827148438\n",
            "random\n",
            "Game Over!\n",
            "Episode: 645201/1000000, Action: 0, Loss: 0.11426807940006256, Epsilon 0.03554452000000001, Reward: 0.3, Q-value: 0.830946683883667\n",
            "random\n",
            "Episode: 645251/1000000, Action: 0, Loss: 0.10458144545555115, Epsilon 0.035539525, Reward: 0.3, Q-value: 1.1570725440979004\n",
            "random\n",
            "Episode: 645301/1000000, Action: 0, Loss: 0.08450697362422943, Epsilon 0.03553453, Reward: 0.3, Q-value: 0.8115878701210022\n",
            "random\n",
            "Game Over!\n",
            "Episode: 645351/1000000, Action: 0, Loss: 0.08499079197645187, Epsilon 0.03552953500000001, Reward: 0.3, Q-value: 0.8996250033378601\n",
            "random\n",
            "Episode: 645401/1000000, Action: 0, Loss: 0.08522173762321472, Epsilon 0.03552454, Reward: 0.3, Q-value: 0.6988836526870728\n",
            "random\n",
            "Episode: 645451/1000000, Action: 0, Loss: 0.08502204716205597, Epsilon 0.035519545, Reward: 0.3, Q-value: 0.9672935009002686\n",
            "Game Over!\n",
            "random\n",
            "random\n",
            "Episode: 645501/1000000, Action: 0, Loss: 0.0836932510137558, Epsilon 0.035514550000000006, Reward: 0.3, Q-value: 0.7223736047744751\n",
            "random\n",
            "random\n",
            "Episode: 645551/1000000, Action: 0, Loss: 0.08532273769378662, Epsilon 0.035509555000000005, Reward: 0.3, Q-value: 0.8144801259040833\n",
            "random\n",
            "random\n",
            "random\n",
            "Episode: 645601/1000000, Action: 0, Loss: 0.08559489995241165, Epsilon 0.03550456, Reward: 0.3, Q-value: 0.6745761632919312\n",
            "random\n",
            "random\n",
            "Game Over!\n",
            "random\n",
            "random\n",
            "random\n",
            "Episode: 645651/1000000, Action: 0, Loss: 0.08710641413927078, Epsilon 0.035499565000000004, Reward: 0.3, Q-value: 0.7357879877090454\n",
            "random\n",
            "random\n",
            "Episode: 645701/1000000, Action: 0, Loss: 0.0835338905453682, Epsilon 0.03549457, Reward: 0.3, Q-value: 0.8608120679855347\n",
            "random\n",
            "random\n",
            "random\n",
            "Episode: 645751/1000000, Action: 0, Loss: 0.0842474102973938, Epsilon 0.03548957500000001, Reward: 0.3, Q-value: 0.8082111477851868\n",
            "Game Over!\n",
            "Game Over!\n",
            "random\n",
            "random\n",
            "Episode: 645801/1000000, Action: 0, Loss: 0.08649958670139313, Epsilon 0.03548458, Reward: 0.3, Q-value: 0.8438633680343628\n",
            "random\n",
            "random\n",
            "Episode: 645851/1000000, Action: 0, Loss: 0.08403797447681427, Epsilon 0.035479585, Reward: 0.3, Q-value: 0.5776258111000061\n",
            "random\n",
            "Episode: 645901/1000000, Action: 0, Loss: 0.08596806228160858, Epsilon 0.03547459000000001, Reward: 0.3, Q-value: 0.5809682607650757\n",
            "random\n",
            "Game Over!\n",
            "random\n",
            "Episode: 645951/1000000, Action: 0, Loss: 0.08645869791507721, Epsilon 0.03546959500000001, Reward: 0.3, Q-value: 0.5505386590957642\n",
            "random\n",
            "random\n",
            "Episode: 646001/1000000, Action: 0, Loss: 0.09120133519172668, Epsilon 0.0354646, Reward: 0.3, Q-value: 0.8358343839645386\n",
            "random\n",
            "random\n",
            "random\n",
            "Episode: 646051/1000000, Action: 0, Loss: 0.08473420143127441, Epsilon 0.035459605000000005, Reward: 0.3, Q-value: 0.6325092315673828\n",
            "Game Over!\n",
            "random\n",
            "Episode: 646101/1000000, Action: 0, Loss: 0.08571906387805939, Epsilon 0.035454610000000004, Reward: 0.3, Q-value: 0.49217531085014343\n",
            "random\n",
            "random\n",
            "Episode: 646151/1000000, Action: 0, Loss: 0.0916103646159172, Epsilon 0.035449615000000004, Reward: 0.3, Q-value: 0.4822337031364441\n",
            "Game Over!\n",
            "Episode: 646201/1000000, Action: 0, Loss: 0.08295048028230667, Epsilon 0.03544462, Reward: 0.3, Q-value: 0.4691183269023895\n",
            "random\n",
            "random\n",
            "Episode: 646251/1000000, Action: 0, Loss: 0.11052165180444717, Epsilon 0.035439625, Reward: 0.3, Q-value: 0.697117269039154\n",
            "random\n",
            "Episode: 646301/1000000, Action: 0, Loss: 0.0835273265838623, Epsilon 0.03543463, Reward: 0.3, Q-value: 0.5668717622756958\n",
            "random\n",
            "random\n",
            "Game Over!\n",
            "random\n",
            "Episode: 646351/1000000, Action: 0, Loss: 0.08591637760400772, Epsilon 0.03542963500000001, Reward: 0.3, Q-value: 0.45434311032295227\n",
            "random\n",
            "random\n",
            "random\n",
            "Episode: 646401/1000000, Action: 0, Loss: 0.08413001149892807, Epsilon 0.03542464, Reward: 0.3, Q-value: 0.4610479176044464\n",
            "random\n",
            "Episode: 646451/1000000, Action: 0, Loss: 0.08628801256418228, Epsilon 0.03541964500000001, Reward: 0.3, Q-value: 0.7384477853775024\n",
            "random\n",
            "Game Over!\n",
            "random\n",
            "random\n",
            "random\n",
            "Episode: 646501/1000000, Action: 0, Loss: 0.08586004376411438, Epsilon 0.035414650000000006, Reward: 0.3, Q-value: 0.458189457654953\n",
            "random\n",
            "Episode: 646551/1000000, Action: 0, Loss: 0.11595781147480011, Epsilon 0.035409655000000005, Reward: 0.3, Q-value: 0.4203636050224304\n",
            "random\n",
            "Episode: 646601/1000000, Action: 0, Loss: 0.08124102652072906, Epsilon 0.035404660000000004, Reward: 0.3, Q-value: 0.5395123362541199\n",
            "random\n",
            "random\n",
            "Episode: 646651/1000000, Action: 0, Loss: 0.08981567621231079, Epsilon 0.035399665000000004, Reward: 0.3, Q-value: 0.5450431704521179\n",
            "Episode: 646701/1000000, Action: 0, Loss: 0.08520064502954483, Epsilon 0.03539467, Reward: 0.3, Q-value: 0.4118330776691437\n",
            "Game Over!\n",
            "Episode: 646751/1000000, Action: 0, Loss: 0.08558778464794159, Epsilon 0.035389675, Reward: 0.3, Q-value: 0.4094288945198059\n",
            "random\n",
            "Episode: 646801/1000000, Action: 0, Loss: 0.08697383850812912, Epsilon 0.03538468, Reward: 0.3, Q-value: 0.5512439608573914\n",
            "random\n",
            "random\n",
            "Episode: 646851/1000000, Action: 0, Loss: 0.0859118103981018, Epsilon 0.035379685, Reward: 0.3, Q-value: 0.4290432631969452\n",
            "random\n",
            "random\n",
            "random\n",
            "Episode: 646901/1000000, Action: 0, Loss: 0.08637423068284988, Epsilon 0.03537469000000001, Reward: 0.3, Q-value: 0.490901917219162\n",
            "random\n",
            "Game Over!\n",
            "Episode: 646951/1000000, Action: 0, Loss: 0.08981902152299881, Epsilon 0.035369695, Reward: 0.3, Q-value: 0.7173229455947876\n",
            "random\n",
            "random\n",
            "random\n",
            "Episode: 647001/1000000, Action: 0, Loss: 0.0837247297167778, Epsilon 0.035364700000000006, Reward: 0.3, Q-value: 0.7092917561531067\n",
            "random\n",
            "random\n",
            "random\n",
            "random\n",
            "random\n",
            "random\n",
            "random\n",
            "random\n",
            "Episode: 647051/1000000, Action: 0, Loss: 0.08778683841228485, Epsilon 0.035359705000000005, Reward: 0.3, Q-value: 0.4595065414905548\n",
            "random\n",
            "random\n",
            "Episode: 647101/1000000, Action: 0, Loss: 0.08501642942428589, Epsilon 0.035354710000000004, Reward: 0.3, Q-value: 0.6226940751075745\n",
            "random\n",
            "random\n",
            "random\n",
            "random\n",
            "Episode: 647151/1000000, Action: 0, Loss: 0.1165844202041626, Epsilon 0.035349715000000004, Reward: 0.3, Q-value: 0.6854750514030457\n",
            "random\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "display Surface quit",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-11-e0da9a6a734e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-11-e0da9a6a734e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(episodes)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mnext_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendgame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_game\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnextframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;31m#next_image = torch.from_numpy(np.expand_dims(np.transpose(next_image,(2,0,1)),0))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;31m#next_image = next_image.float()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Nikhil\\Documents\\Python_Codes\\Dino-RL\\game.py\u001b[0m in \u001b[0;36mnextframe\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpygame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msurfarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISPLAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Nikhil\\Documents\\Python_Codes\\Dino-RL\\game.py\u001b[0m in \u001b[0;36mrender_all\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISPLAY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackground_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcacti\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcacti\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISPLAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31merror\u001b[0m: display Surface quit"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}