{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9e/sbXcUajLwRA/hfMGdQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhil-Khetani/Dino-RL/blob/main/train_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VkFrzP7Dau8",
        "outputId": "71f9bf04-3a1f-4d30-d8ab-85f4f85fb953"
      },
      "source": [
        "!pip install pygame"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygame\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/da/4ff439558641a26dd29b04c25947e6c0ace041f56b2aa2ef1134edab06b8/pygame-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (11.8MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8MB 271kB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkoe3seEDgUh",
        "outputId": "472b256a-577e-4967-9c19-b60c20c3d033",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import cv2\r\n",
        "import time \r\n",
        "import os, sys\r\n",
        "import game\r\n",
        "import math\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "from collections import namedtuple\r\n",
        "from itertools import count\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision.transforms as T\r\n",
        "import pygame\r\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pygame 2.0.1 (SDL 2.0.14, Python 3.6.9)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuTd3rk_Dmct"
      },
      "source": [
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkpZyQ-9Dq48"
      },
      "source": [
        "\r\n",
        "\r\n",
        "\r\n",
        "DISPLAY_HEIGHT=400\r\n",
        "DISPLAY_WIDTH=400\r\n",
        "STATE_HEIGHT = DISPLAY_HEIGHT-1\r\n",
        "STATE_WIDTH = DISPLAY_WIDTH-1\r\n",
        "\r\n",
        "pygame.init()\r\n",
        "\r\n",
        "image_size=84\r\n",
        "batch_size=32\r\n",
        "lr=1e-6\r\n",
        "gamma=0.99\r\n",
        "initial_epsilon=0.1\r\n",
        "final_epsilon=1e-4\r\n",
        "num_iters=2000000\r\n",
        "replay_memory_size=50000"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAC26h3MFwMq"
      },
      "source": [
        "\r\n",
        "Transition = namedtuple('Transition',('state', 'action', 'next_state', 'reward'))\r\n",
        "\r\n",
        "def pre_processing(image, width, height):\r\n",
        "    image = cv2.cvtColor(cv2.resize(image, (width, height)), cv2.COLOR_BGR2GRAY)\r\n",
        "    _, image = cv2.threshold(image, 1, 255, cv2.THRESH_BINARY)\r\n",
        "    return image[None, :, :].astype(np.float32)\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkoOWRKMFV71"
      },
      "source": [
        "\r\n",
        "class DeepQNetwork(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(DeepQNetwork, self).__init__()\r\n",
        "\r\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(4, 32, kernel_size=8, stride=4), nn.ReLU(inplace=True))\r\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(inplace=True))\r\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1), nn.ReLU(inplace=True))\r\n",
        "\r\n",
        "        self.fc1 = nn.Sequential(nn.Linear(7 * 7 * 64, 512), nn.ReLU(inplace=True))\r\n",
        "        self.fc2 = nn.Linear(512, 2)\r\n",
        "        self._create_weights()\r\n",
        "\r\n",
        "    def _create_weights(self):\r\n",
        "        for m in self.modules():\r\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\r\n",
        "                nn.init.uniform(m.weight, -0.01, 0.01)\r\n",
        "                nn.init.constant_(m.bias, 0)\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        output = self.conv1(input)\r\n",
        "        output = self.conv2(output)\r\n",
        "        output = self.conv3(output)\r\n",
        "        output = output.view(output.size(0), -1)\r\n",
        "        output = self.fc1(output)\r\n",
        "        output = self.fc2(output)\r\n",
        "\r\n",
        "        return output"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49ZgrRJgFcFM",
        "outputId": "1e128ef4-5117-4c9b-a0d2-7b45ec5b6fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "source": [
        "\r\n",
        "def train(episodes):\r\n",
        "    real_time_start = time.time()\r\n",
        "    CPU_time_start = time.process_time()\r\n",
        "    model = DeepQNetwork()\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\r\n",
        "    criterion = torch.nn.MSELoss()\r\n",
        "    current_game = game.DinoGame(None,400,400)\r\n",
        "    image, reward, endgame = current_game.nextframe(0)\r\n",
        "    \r\n",
        "    image = pre_processing(image, 84,84)\r\n",
        "    #image = torch.from_numpy(np.expand_dims(np.transpose(image,(2,0,1)),0))\r\n",
        "    image = torch.from_numpy(image)\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        model.cuda()\r\n",
        "        image = image.cuda()\r\n",
        "    #image=image.float()\r\n",
        "    state=torch.cat(tuple(image for _ in range (4)))[None, :, :, :]\r\n",
        "    #print(state.shape)\r\n",
        "    replay_memory = []\r\n",
        "    episode = 0\r\n",
        "    checkpoint_real_time_elapsed = 0\r\n",
        "    checkpoint_CPU_time_elapsed = 0\r\n",
        "\r\n",
        "\r\n",
        "    for i in reversed(range(100)):\r\n",
        "      print(i)\r\n",
        "      checkpoint_path = \"checkpoint_{}.pt\".format(i*1000)\r\n",
        "      if os.path.exists(checkpoint_path):\r\n",
        "          checkpoint = torch.load(checkpoint_path)\r\n",
        "          model.load_state_dict(checkpoint['model_state_dict'])\r\n",
        "          optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n",
        "          episode = checkpoint['checkpoint_episode']\r\n",
        "          loss = checkpoint['loss']\r\n",
        "          checkpoint_real_time_elapsed = checkpoint['real_time_elapsed']\r\n",
        "          checkpoint_CPU_time_elapsed = checkpoint['CPU_time_elapsed']\r\n",
        "          print(\"checkpoint loaded\")\r\n",
        "          print(\"checkpoint episode:\" + str(episode))\r\n",
        "          break\r\n",
        "    \r\n",
        "    while episode<episodes:\r\n",
        "        pred = model(state)[0]\r\n",
        "        epsilon = final_epsilon+((episodes-episode)*(initial_epsilon-final_epsilon)/episodes)\r\n",
        "        take_random_action = random.random()<=epsilon\r\n",
        "        if take_random_action:\r\n",
        "            print('random')\r\n",
        "            action = random.randint(0,1)\r\n",
        "        else:\r\n",
        "            action=torch.argmax(pred)\r\n",
        "\r\n",
        "        next_image, reward, endgame = current_game.nextframe(action)\r\n",
        "        #next_image = torch.from_numpy(np.expand_dims(np.transpose(next_image,(2,0,1)),0))\r\n",
        "        #next_image = next_image.float()\r\n",
        "        #next_state = torch.cat((state.squeeze(0)[3:,:,:], next_image))\r\n",
        "\r\n",
        "        next_image = pre_processing(next_image, 84,84)\r\n",
        "\r\n",
        "        #action = action.unsqueeze(0)\r\n",
        "        #reward = torch.from_numpy(np.array([reward],dtype=np.float32)).unsqueeze(0)\r\n",
        "        next_image = torch.from_numpy(next_image)\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            next_image = next_image.cuda()\r\n",
        "        next_state = torch.cat((state[0, 1:, :, :], next_image))[None, :, :, :]\r\n",
        "\r\n",
        "        replay_memory.append([state, action, reward, next_state, endgame])\r\n",
        "        if len(replay_memory) > replay_memory_size:\r\n",
        "            del replay_memory[0]\r\n",
        "        batch = random.sample(replay_memory, min(len(replay_memory), batch_size))\r\n",
        "        state_batch, action_batch, reward_batch, next_state_batch, terminal_batch = zip(*batch)\r\n",
        "        state_batch = torch.cat(tuple(state for state in state_batch))\r\n",
        "        action_batch = torch.from_numpy(\r\n",
        "            np.array([[1, 0] if action == 0 else [0, 1] for action in action_batch], dtype=np.float32))\r\n",
        "        reward_batch = torch.from_numpy(np.array(reward_batch, dtype=np.float32)[:, None])\r\n",
        "        next_state_batch = torch.cat(tuple(state for state in next_state_batch))\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            state_batch = state_batch.cuda()\r\n",
        "            action_batch = action_batch.cuda()\r\n",
        "            reward_batch = reward_batch.cuda()\r\n",
        "            next_state_batch = next_state_batch.cuda()\r\n",
        "        \r\n",
        "        current_prediction_batch = model(state_batch)\r\n",
        "        next_prediction_batch = model(next_state_batch)\r\n",
        "\r\n",
        "        y_batch = torch.cat(\r\n",
        "            tuple(reward if terminal else reward + gamma * torch.max(prediction) for reward, terminal, prediction in\r\n",
        "                  zip(reward_batch, terminal_batch, next_prediction_batch)))\r\n",
        "        q_value = torch.sum(current_prediction_batch * action_batch, dim=1)\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss = criterion(q_value, y_batch)\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        state = next_state\r\n",
        "        \r\n",
        "        if episode %50 == 0:\r\n",
        "            print(\"Episode: {}/{}, Action: {}, Loss: {}, Epsilon {}, Reward: {}, Q-value: {}\".format(\r\n",
        "            episode + 1, episodes, action, loss, epsilon, reward, torch.max(pred)))\r\n",
        "        episode+=1\r\n",
        "\r\n",
        "        if episode % 5000 == 0:\r\n",
        "            real_time_elapsed = time.time()-real_time_start + checkpoint_real_time_elapsed\r\n",
        "            CPU_time_elapsed =time.process_time()-CPU_time_start + checkpoint_CPU_time_elapsed\r\n",
        "            print(\"Real time elapsed : {}, CPU time elapsed : {}\".format(real_time_elapsed,CPU_time_elapsed))\r\n",
        "            checkpoint_path = \"checkpoint_{}.pt\".format(episode)\r\n",
        "            torch.save({\r\n",
        "            'checkpoint_episode': episode,\r\n",
        "            'model_state_dict': model.state_dict(),\r\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\r\n",
        "            'loss':loss,\r\n",
        "            'real_time_elapsed' : real_time_elapsed,\r\n",
        "            'CPU_time_elapsed' : CPU_time_elapsed\r\n",
        "            }, checkpoint_path)\r\n",
        "\r\n",
        "\r\n",
        "train(1000000)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random\n",
            "random\n",
            "Episode: 11251/1000000, Action: 0, Loss: 0.07971564680337906, Epsilon 0.09887612500000001, Reward: 0.3, Q-value: 0.68695467710495\n",
            "random\n",
            "random\n",
            "random\n",
            "random\n",
            "random\n",
            "random\n",
            "Episode: 11301/1000000, Action: 1, Loss: 0.07699714601039886, Epsilon 0.09887113, Reward: 0.2, Q-value: 0.6736316084861755\n",
            "random\n",
            "random\n",
            "Game Over!\n",
            "Game Over!\n",
            "random\n",
            "random\n",
            "Episode: 11351/1000000, Action: 0, Loss: 0.0799194872379303, Epsilon 0.09886613500000001, Reward: 0.3, Q-value: 0.6776009798049927\n",
            "random\n",
            "random\n",
            "random\n",
            "random\n",
            "random\n",
            "random\n",
            "Episode: 11401/1000000, Action: 0, Loss: 0.10666875541210175, Epsilon 0.09886114, Reward: 0.3, Q-value: 0.656002402305603\n",
            "random\n",
            "random\n",
            "random\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-338fa4ebea21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-338fa4ebea21>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(episodes)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}